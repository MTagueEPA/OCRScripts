{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1e82c-eadc-4c17-b3a5-76bab508b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tesserocr import OEM,PSM, PyTessBaseAPI\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ocr_utils\n",
    "import sys\n",
    "sys.path.append('table-transformer-tatr')\n",
    "\n",
    "from src.inference import TableExtractionPipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14fffd-8c3c-4fd6-b917-f4992b6ea9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that need to be made\n",
    "# pdf_directory = 'test'\n",
    "directory = 'test'\n",
    "subdirectories = ['csvs', 'processed_txts', 'txts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd34d2a-6558-453b-a4a6-82d386d7a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate table extraction pipeline\n",
    "pipe = TableExtractionPipeline(\n",
    "    det_config_path='src/detection_config.json', det_device='cpu',\n",
    "    det_model_path='pubtables1m_detection_detr_r18.pth',\n",
    "    str_config_path='src/structure_config.json', str_device='cpu',\n",
    "    str_model_path='TATR-v1.1-All-msft.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6889c07-ac74-41bc-8d97-59d8c8c57eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory with needed subfolders\n",
    "try:\n",
    "    for subdir in subdirectories:\n",
    "        os.makedirs(f\"./{directory}/{subdir}\", exist_ok=False)\n",
    "    print(f\"Directory {directory} created successfully with subfolders\")\n",
    "except OSError:\n",
    "    print(f\"Directory {directory} can not be created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da7491-2f12-4535-beb8-2d90bc82bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all pdf files\n",
    "pdf_files = list(Path(\"  \").glob('*.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db521e22-71b3-444f-9d64-d7dab9a2061f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all PDF files\n",
    "for pdf in tqdm(pdf_files):\n",
    "    # Initialize empty strings for processed and unprocessed text\n",
    "    text_processed = ''\n",
    "    text_auto = ''\n",
    "    \n",
    "    # Extract the filename from the pdf path\n",
    "    filename = pdf.stem\n",
    "    \n",
    "    # Get all pages from the current PDF file\n",
    "    PAGES = ocr_utils.get_pages(pdf)\n",
    "    \n",
    "    # Iterate over all pages\n",
    "    for page_num, page in enumerate(tqdm(PAGES)):\n",
    "        page_num = page_num+1\n",
    "        try:\n",
    "            # Correct the orientation and skew of the page\n",
    "            PAGE = ocr_utils.orientation_and_deskew(page)\n",
    "        except Exception as e:\n",
    "            # Skip the current page if an error occurs and print the error message\n",
    "            print(f\"Skipping {page_num} due to {e}\")\n",
    "            continue\n",
    "            \n",
    "        with PyTessBaseAPI(lang='eng', psm=PSM.AUTO, oem=OEM.DEFAULT) as api:\n",
    "            # Process the page and extract text\n",
    "            processed = ocr_utils.process_text_page(PAGE)\n",
    "            api.SetImage(processed)\n",
    "            api.Recognize()\n",
    "            next_text_processed = api.GetUTF8Text()\n",
    "            \n",
    "            # Add the extracted text to the processed text string\n",
    "            text_processed += f\"\\n\\n PAGE: {page_num} \\n\\n {next_text_processed}\"\n",
    "            \n",
    "        with PyTessBaseAPI(lang='eng', psm=PSM.AUTO, oem=OEM.DEFAULT) as api:\n",
    "            # Extract text from the unprocessed page\n",
    "            api.SetImage(PAGE)\n",
    "            api.Recognize()\n",
    "            next_text = api.GetUTF8Text()\n",
    "            \n",
    "            # Add the extracted text to the unprocessed text string\n",
    "            text_auto += f\"\\n\\n PAGE: {page_num} \\n\\n {next_text}\"\n",
    "\n",
    "        # Convert the image to a list of words\n",
    "        toks = ocr_utils.ocr_image_to_word_list(PAGE)\n",
    "        # Detect tables in the page\n",
    "        det_tab = pipe.detect(PAGE, tokens=toks, out_crops=True, out_objects=True)\n",
    "        # If tables are detected in the page\n",
    "        if det_tab['crops']:\n",
    "            for i, crop in enumerate(det_tab['crops']):\n",
    "                # Convert the table image to a list of words\n",
    "                table_tokens = ocr_utils.ocr_image_to_word_list(crop['image'])\n",
    "                # Recognize the table and extract its contents\n",
    "                extracted_table = pipe.recognize(crop['image'], table_tokens, out_objects=True, out_cells=True, out_csv=True, out_html=True)\n",
    "                html_table = io.StringIO(extracted_table['html'][0])\n",
    "                try:\n",
    "                    # Convert the HTML table to a pandas DataFrame\n",
    "                    table_df = pd.read_html(html_table)\n",
    "                except:\n",
    "                    continue\n",
    "                table = table_df[0]\n",
    "                # Save the table as a CSV file\n",
    "                table.to_csv(f'{directory}/csvs/{filename}_page_{page_num}_table_{i}.csv', index=False)\n",
    "                \n",
    "    # Write the unprocessed text to a file\n",
    "    with open(f\"{directory}/txts/{filename}.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(text_auto)\n",
    "\n",
    "    # Write the processed text to a file\n",
    "    with open(f\"{directory}/processed_txts/{filename}.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337c0fa-3120-4b18-ba0c-df79732e788d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
